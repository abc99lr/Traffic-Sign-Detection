{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Sign Detection based on Faster R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project of ECE544NA @ UIUC <br> \n",
    "Member: Yuan Cheng, Rui Lan, and Jiaxi Nie <br> \n",
    "Time: Nov 2017 <br> \n",
    "Dataset: GTSDB <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------Import Libraries-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------Load Dataset-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(input_path):\n",
    "    found_bg = False\n",
    "    all_imgs = {}\n",
    "\n",
    "    classes_count = {}\n",
    "\n",
    "    class_mapping = {}\n",
    "\n",
    "    visualise = True\n",
    "    \n",
    "    with open(input_path, 'r') as f:\n",
    "\n",
    "        print('Parsing annotation files')\n",
    "\n",
    "        for line in f:\n",
    "            line_split = line.strip().split(',')\n",
    "            (filename,x1,y1,x2,y2,class_name) = line_split\n",
    "\n",
    "            if class_name not in classes_count:\n",
    "                classes_count[class_name] = 1\n",
    "            else:\n",
    "                classes_count[class_name] += 1\n",
    "\n",
    "            if class_name not in class_mapping:\n",
    "                if class_name == 'bg' and found_bg == False:\n",
    "                    print('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
    "                    found_bg = True\n",
    "                class_mapping[class_name] = len(class_mapping)\n",
    "\n",
    "            if filename not in all_imgs:\n",
    "                \n",
    "                all_imgs[filename] = {}\n",
    "                \n",
    "                # -------------CAN EDIT HERE-------------\n",
    "                img = cv2.imread(os.path.dirname(input_path) + '/' + filename)\n",
    "                \n",
    "                (rows,cols) = img.shape[:2]\n",
    "                all_imgs[filename]['filepath'] = filename\n",
    "                all_imgs[filename]['width'] = cols\n",
    "                all_imgs[filename]['height'] = rows\n",
    "                all_imgs[filename]['bboxes'] = []\n",
    "                if np.random.randint(0,6) > 0:\n",
    "                    all_imgs[filename]['imageset'] = 'trainval'\n",
    "                else:\n",
    "                    all_imgs[filename]['imageset'] = 'test'\n",
    "\n",
    "            all_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
    "\n",
    "\n",
    "        all_data = []\n",
    "        for key in all_imgs:\n",
    "            all_data.append(all_imgs[key])\n",
    "        \n",
    "        # make sure the bg class is last in the list\n",
    "        if found_bg:\n",
    "            if class_mapping['bg'] != len(class_mapping) - 1:\n",
    "                key_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
    "                val_to_switch = class_mapping['bg']\n",
    "                class_mapping['bg'] = len(class_mapping) - 1\n",
    "                class_mapping[key_to_switch] = val_to_switch\n",
    "        \n",
    "        return all_data, classes_count, class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchor_gt(all_img_data, class_count, C, img_length_calc_function, backend, mode='train'):\n",
    "\n",
    "    # The following line is not useful with Python 3.5, it is kept for the legacy\n",
    "    # all_img_data = sorted(all_img_data)\n",
    "\n",
    "    sample_selector = SampleSelector(class_count)\n",
    "\n",
    "    while True:\n",
    "        if mode == 'train':\n",
    "            np.random.shuffle(all_img_data)\n",
    "\n",
    "        for img_data in all_img_data:\n",
    "            try:\n",
    "\n",
    "                if C.balanced_classes and sample_selector.skip_sample_for_balanced_class(img_data):\n",
    "                    continue\n",
    "\n",
    "                # read in image, and optionally add augmentation\n",
    "\n",
    "                if mode == 'train':\n",
    "                    img_data_aug, x_img = data_augment.augment(img_data, C, augment=True)\n",
    "                else:\n",
    "                    img_data_aug, x_img = data_augment.augment(img_data, C, augment=False)\n",
    "\n",
    "                (width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
    "                (rows, cols, _) = x_img.shape\n",
    "\n",
    "                assert cols == width\n",
    "                assert rows == height\n",
    "\n",
    "                # get image dimensions for resizing\n",
    "                (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
    "\n",
    "                # resize the image so that smalles side is length = 600px\n",
    "                x_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                try:\n",
    "                    y_rpn_cls, y_rpn_regr = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # Zero-center by mean pixel, and preprocess image\n",
    "\n",
    "                x_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n",
    "                x_img = x_img.astype(np.float32)\n",
    "                x_img[:, :, 0] -= C.img_channel_mean[0]\n",
    "                x_img[:, :, 1] -= C.img_channel_mean[1]\n",
    "                x_img[:, :, 2] -= C.img_channel_mean[2]\n",
    "                x_img /= C.img_scaling_factor\n",
    "\n",
    "                x_img = np.transpose(x_img, (2, 0, 1))\n",
    "                x_img = np.expand_dims(x_img, axis=0)\n",
    "\n",
    "                y_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
    "\n",
    "                if backend == 'tf':\n",
    "                    x_img = np.transpose(x_img, (0, 2, 3, 1))\n",
    "                    y_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
    "                    y_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
    "\n",
    "                yield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------CORE-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n"
     ]
    }
   ],
   "source": [
    "# Read dataset + Generate dicts for images and labels\n",
    "all_imgs, classes_count, class_mapping = get_data('../dataset/PNG_train/gt.txt')\n",
    "\n",
    "# Add the background class to the dicts \n",
    "if 'bg' not in classes_count:\n",
    "    classes_count['bg'] = 0\n",
    "    class_mapping['bg'] = len(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images per class:\n",
      "{'0': 4,\n",
      " '1': 79,\n",
      " '10': 80,\n",
      " '11': 38,\n",
      " '12': 85,\n",
      " '13': 83,\n",
      " '14': 32,\n",
      " '15': 15,\n",
      " '16': 8,\n",
      " '17': 29,\n",
      " '18': 38,\n",
      " '19': 2,\n",
      " '2': 81,\n",
      " '20': 9,\n",
      " '21': 5,\n",
      " '22': 13,\n",
      " '23': 20,\n",
      " '24': 5,\n",
      " '25': 31,\n",
      " '26': 18,\n",
      " '27': 3,\n",
      " '28': 14,\n",
      " '29': 5,\n",
      " '3': 30,\n",
      " '30': 16,\n",
      " '31': 2,\n",
      " '32': 8,\n",
      " '33': 16,\n",
      " '34': 12,\n",
      " '35': 20,\n",
      " '36': 9,\n",
      " '37': 2,\n",
      " '38': 88,\n",
      " '39': 6,\n",
      " '4': 68,\n",
      " '40': 10,\n",
      " '41': 7,\n",
      " '42': 11,\n",
      " '5': 53,\n",
      " '6': 19,\n",
      " '7': 41,\n",
      " '8': 57,\n",
      " '9': 41,\n",
      " 'bg': 0}\n",
      "Num classes (including bg) = 44\n"
     ]
    }
   ],
   "source": [
    "print('Training images per class:')\n",
    "pprint.pprint(classes_count)\n",
    "print('Num classes (including bg) = {}'.format(len(classes_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train samples 622\n",
      "Num val samples 119\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(all_imgs)\n",
    "\n",
    "num_imgs = len(all_imgs)\n",
    "\n",
    "train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "\n",
    "print('Num train samples {}'.format(len(train_imgs)))\n",
    "print('Num val samples {}'.format(len(val_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}